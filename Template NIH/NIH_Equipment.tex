\section*{EQUIPMENT}



\noindent\textbf{Dr. Name, Baylor University}

Baylor University maintains three labs with 70 computers, and a complete suite of software include MATLAB and all toolboxes, and software development environments for all major languages.  Additionally, each of Dr. Olafsen's graduate students has a dedicated workspace at the BRIC with a computer, multiple monitors, and a complete suite of software as outlined above.

Baylor University recently constructed a class 1,000 cleanroom located at the BRIC.  The cleanroom facility is equipped with a mask aligner, magnetron DC/RF sputterer, surface profilometer, plasma surface treatment system, microplotter, wet bench, fume hoods, microscopes, etc. for materials and device fabrication.

Professor NAME's LABNAME Laboratory contains equipment for ...


The \textbf{Baylor University Tardis cluster}, is composed of 5 dual 12-core Xeon processors each with 64GB RAM, a 1TB Solid State HD, a 4TB HD, and connected with 40Gb Infiniband and two 1Gb Ethernets. Four of the nodes have 4 NVIDIA K-40 GPUs each, for a total of 16 K-40 GPUs and over 46,000 CUDA cores. The final node serves as the head node of the cluster and has an additional 4TB HD, for a total of 9TB of disk space. Tardis also has access to Baylor University's network data server with 100TB available.  Two dedicated development workstations for testing code are connected by a private one gig Ethernet network to the cluster. The workstations are dual 6-core Xeons with NVIDIA 780 GPUs, 32GB RAM and 3TB of hard disk.

Baylor University recently installed a major new update of the \textbf{Kodiak cluster}, which will consist of 67 nodes with dual Xeon E5-295 v4, 2.1 GHz, 18-core processors with 256GB RAM, 240GB SSD.  Two of these nodes will additionally contain dual Nvidia P100 GPUs.  Two more nodes will use Intel Knights Landing 64-core 1.3GHz processors instead of the Xeon processors.  All nodes are connected by Intel Omni-Path 100Gb/s network interface for the primary cluster interconnect, and have an 1Gb/s Ethernet management network.   The new dual Xeon compute nodes will have an aggregate peak performance of 77.4TF (TeraFLOPS), the KNL nodes will have an aggregate peak vector performance of 6TF (double precision), and the GPU nodes will have an aggregate peak performance of at least 9.4TF (double precision) for a total peak performance of at least 92.8TF. 